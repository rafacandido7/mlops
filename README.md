# Projeto MLOps: Pipeline de Machine Learning com Metaflow e Spark MLlib em K3s

## üìö Vis√£o Geral

Este projeto implementa um pipeline de Machine Learning de ponta a ponta, utilizando Metaflow para orquestra√ß√£o e **Apache Spark (com MLlib) para processamento de dados distribu√≠do e treinamento de modelos**. Toda a infraestrutura √© executada em um cluster K3s, gerenciado via Rancher, com componentes adicionais como Harbor para registro de imagens Docker e MinIO para armazenamento de objetos.

O objetivo √© criar um ambiente de MLOps robusto e escal√°vel, adequado para desenvolvimento, experimenta√ß√£o e potencial implanta√ß√£o de modelos de Machine Learning, com foco na arquitetura e infraestrutura e utilizando o poder do Spark de ponta a ponta.

## ‚ú® Funcionalidades Principais

* **Orquestra√ß√£o de Pipeline com Metaflow:** Defini√ß√£o e execu√ß√£o de fluxos de trabalho de ML complexos.
* **Interface Gr√°fica do Metaflow (Metaflow UI):** Visualiza√ß√£o e inspe√ß√£o de execu√ß√µes de pipelines, steps e artefatos.
* **Processamento de Dados com PySpark:** Capacidade de processar grandes volumes de dados (arquivos Parquet) de forma distribu√≠da.
* **Treinamento de Modelos com Spark MLlib:** Treinamento de modelos de Machine Learning diretamente em Spark DataFrames, aproveitando a computa√ß√£o distribu√≠da.
* **Execu√ß√£o em Kubernetes (K3s):** Os steps do Metaflow s√£o executados como pods no K3s, permitindo escalabilidade e isolamento.
* **Gerenciamento Centralizado de Cluster com Rancher:** Facilidade para gerenciar o cluster K3s, namespaces, deployments e outros recursos.
* **Registro Privado de Imagens com Harbor:** Armazenamento seguro e versionamento de imagens Docker customizadas.
* **Armazenamento de Objetos com MinIO:** Utilizado para armazenar dados brutos, datasets processados, artefatos do Metaflow e modelos Spark MLlib treinados.
* **Valida√ß√£o de Dados com Great Expectations:** Garantia da qualidade e integridade dos dados ao longo do pipeline (aplicada em Spark DataFrames).
* **Persist√™ncia de Dados Robusta com Longhorn:** Storage distribu√≠do e replicado para os servi√ßos stateful.
* **Gerenciamento de Certificados TLS com Cert-Manager:** Emiss√£o e renova√ß√£o autom√°tica de certificados TLS para os servi√ßos expostos.

## üõ†Ô∏è Stack Tecnol√≥gica

* **Virtualiza√ß√£o:** Proxmox (ou qualquer outro hipervisor/ambiente bare-metal)
* **Sistema Operacional das VMs:** Ubuntu Server 22.04 LTS (recomendado)
* **Orquestra√ß√£o de Containers:** K3s
* **Gerenciamento de Cluster Kubernetes:** Rancher
* **Orquestra√ß√£o de Pipeline ML:** Metaflow
* **Processamento de Dados e Treinamento de Modelos ML:** Apache Spark (PySpark com MLlib)
* **Valida√ß√£o de Dados:** Great Expectations
* **Armazenamento de Objetos:** MinIO
* **Registro de Imagens Docker:** Harbor
* **Storage Distribu√≠do para K8s:** Longhorn
* **Ingress Controller:** Traefik (padr√£o do K3s) ou NGINX
* **Gerenciamento de Certificados TLS:** Cert-Manager
* **Banco de Dados para Metaflow:** PostgreSQL
* **Linguagem Principal:** Python 3.10+ (com PySpark)
* **Conteineriza√ß√£o:** Docker

## üìã Pr√©-requisitos

* Acesso a um ambiente de virtualiza√ß√£o (como Proxmox) ou m√°quinas f√≠sicas para as VMs.
* Conhecimento b√°sico de Linux, Docker, Kubernetes e Apache Spark.
* `kubectl` instalado na sua m√°quina local para interagir com o cluster.
* Conta no Docker Hub (ou outro registro p√∫blico) se precisar puxar imagens base n√£o dispon√≠veis localmente.
* Um nome de dom√≠nio (ou subdom√≠nios) configurado para apontar para o IP do seu Ingress no K3s (para acesso aos servi√ßos com TLS).

## üöÄ Configura√ß√£o da Infraestrutura e Deploy

A configura√ß√£o completa da infraestrutura e o deploy dos servi√ßos seguem um processo detalhado. Consulte o arquivo `BACKLOG.md` para um passo a passo minucioso. As etapas principais incluem:

1.  **Prepara√ß√£o das VMs:** Cria√ß√£o e configura√ß√£o das VMs para Rancher, K3s Server e K3s Agents.
2.  **Instala√ß√£o do K3s:** Setup do cluster K3s (1 servidor, m√∫ltiplos agentes).
3.  **Instala√ß√£o do Rancher:** Deploy do Rancher Server e importa√ß√£o do cluster K3s.
4.  **Configura√ß√µes Iniciais no K3s/Rancher:**
    * Cria√ß√£o de Namespaces (`metaflow`, `spark-operator`, `minio`, `harbor`, `cert-manager`, `longhorn-system`, `postgres`).
    * Instala√ß√£o e configura√ß√£o do Ingress Controller e Cert-Manager.
    * Instala√ß√£o e configura√ß√£o do Longhorn como StorageClass.
5.  **Deploy do Harbor:** Instala√ß√£o via Helm (Rancher Apps), configura√ß√£o de Ingress com TLS e persist√™ncia.
6.  **Build da Imagem Docker Customizada:**
    * Cria√ß√£o do `Dockerfile` com Python, Metaflow, **PySpark (que inclui MLlib)** e outras depend√™ncias.
    * Build e push da imagem para o Harbor.
7.  **Deploy dos Servi√ßos Essenciais via Rancher Apps (Helm):**
    * **MinIO:** Configura√ß√£o de persist√™ncia, credenciais e Ingress. Cria√ß√£o de buckets.
    * **PostgreSQL:** Para o backend de metadados do Metaflow.
    * **Metaflow Metadata Service:** Conectado ao PostgreSQL.
    * **Metaflow UI:** Conectada ao Metadata Service e exposta via Ingress com TLS.
    * **Spark Operator:** Para gerenciar `SparkApplication` (se usado diretamente, ou para refer√™ncia se o Spark rodar no pod do Metaflow).
8.  **Cria√ß√£o de Secrets Kubernetes:**
    * `harbor-creds`: Para o K3s puxar a imagem customizada do Harbor.
    * `minio-creds`: Para o Metaflow e Spark acessarem o MinIO.

## üåä Vis√£o Geral do Pipeline Metaflow (`pipeline.py`)

O pipeline de Machine Learning √© orquestrado pelo Metaflow e consiste nos seguintes steps principais, utilizando Spark para processamento e MLlib para treinamento:

1.  **`start`**: Ponto de entrada do pipeline, inicializa par√¢metros.
2.  **`ingest_and_validate_data`**:
    * Conecta-se ao MinIO usando PySpark.
    * L√™ dados brutos em formato Parquet, resultando em um Spark DataFrame.
    * Valida o Spark DataFrame carregado usando Great Expectations.
    * Armazena o Spark DataFrame validado como um artefato do Metaflow (ou seu path no MinIO).
3.  **`preprocess_data`**:
    * Carrega o Spark DataFrame validado.
    * Realiza etapas de pr√©-processamento e engenharia de features usando transformadores do PySpark (ex: `StringIndexer`, `OneHotEncoder`, normaliza√ß√£o).
    * Armazena o Spark DataFrame processado como um artefato.
4.  **`train_spark_ml_model`**:
    * Carrega o Spark DataFrame processado.
    * Utiliza `VectorAssembler` do Spark MLlib para combinar colunas de features em um √∫nico vetor de features.
    * Define um modelo do Spark MLlib (ex: `pyspark.ml.regression.LinearRegression`, `pyspark.ml.classification.RandomForestClassifier`).
    * Opcionalmente, cria um `pyspark.ml.Pipeline` do Spark MLlib incluindo o `VectorAssembler` e o modelo.
    * Treina o modelo/pipeline Spark MLlib (`model = pipeline.fit(trainingData)`).
    * Salva o modelo Spark MLlib treinado diretamente no MinIO (ex: `model.save("s3a://<bucket>/<path>/spark_ml_model")`).
    * Salva o path do modelo no MinIO e metadados relevantes como artefatos do Metaflow.
5.  **`evaluate_model`**:
    * Carrega o modelo Spark MLlib treinado do MinIO.
    * Realiza predi√ß√µes no conjunto de teste (um Spark DataFrame).
    * Avalia o modelo usando `Evaluator`s do Spark MLlib (ex: `RegressionEvaluator`, `BinaryClassificationEvaluator`).
    * Salva as m√©tricas de avalia√ß√£o como artefatos do Metaflow.
6.  **`end`**: Ponto final do pipeline, loga informa√ß√µes de conclus√£o e o path do modelo salvo.

## üèÉ Como Executar o Pipeline

1.  **Configure o Ambiente Metaflow Local:**
    * Certifique-se de que o Metaflow est√° instalado na sua m√°quina de desenvolvimento.
    * Crie ou atualize seu arquivo `~/.metaflowconfig/config.json` (ou `config.json` no diret√≥rio do projeto) para apontar para os servi√ßos no cluster K3s (MinIO como datastore, Metaflow Metadata Service). Veja o exemplo no `BACKLOG.md` (Tarefa 4.1.3).

2.  **Prepare os Dados de Entrada:**
    * Fa√ßa upload dos seus arquivos Parquet de dados brutos para o bucket configurado no MinIO (ex: `s3a://raw-data/caminho/para/dados/`).

3.  **Execute o Pipeline:**
    Navegue at√© o diret√≥rio do projeto que cont√©m o arquivo `pipeline.py` e execute:

    ```bash
    python pipeline.py --environment=conda run --with kubernetes \
        --minio_bucket_raw_data=<SEU_BUCKET_RAW_DATA> \
        --minio_path_raw_data=<CAMINHO_DENTRO_DO_BUCKET> \
        --model_output_bucket=<SEU_BUCKET_DE_MODELOS_NO_MINIO> # Onde os modelos Spark ser√£o salvos
    ```
    * Substitua os valores dos par√¢metros conforme necess√°rio.
    * O `--environment=conda` √© opcional se suas depend√™ncias locais estiverem alinhadas com a imagem Docker.
    * A flag `--with kubernetes` instrui o Metaflow a executar os steps como pods no Kubernetes, usando a imagem Docker e configura√ß√µes definidas.

## üñ•Ô∏è Acessando os Servi√ßos

Ap√≥s o deploy e configura√ß√£o correta dos Ingresses e DNS, os servi√ßos estar√£o acess√≠veis atrav√©s das seguintes URLs (substitua `meudominio.com` pelo seu dom√≠nio configurado):

* **Rancher UI:** `https://rancher.meudominio.com`
* **Harbor UI:** `https://harbor.meudominio.com`
* **MinIO UI:** `https://minio.meudominio.com`
* **Metaflow UI:** `https://metaflow-ui.meudominio.com`

## üîß Configura√ß√µes Importantes

* **Metaflow `config.json`:** Essencial para o cliente Metaflow local se comunicar com os servi√ßos no cluster.
* **Kubernetes Secrets:**
    * `harbor-creds` (namespace `metaflow`): Para que o Kubernetes possa puxar a imagem customizada do seu Harbor privado para os pods dos steps do Metaflow.
    * `minio-creds` (namespace `metaflow`): Para que os steps do Metaflow (rodando como pods com Spark) possam acessar o MinIO para ler dados e salvar artefatos/modelos.

## üìÇ Estrutura do Diret√≥rio (Sugest√£o)
```bash
meu_projeto_mlops/
‚îú‚îÄ‚îÄ pipeline.py             # Script principal do pipeline Metaflow
‚îú‚îÄ‚îÄ Dockerfile              # Define a imagem customizada para os steps do Metaflow
‚îú‚îÄ‚îÄ config.json             # Configura√ß√£o local do Metaflow (pode estar em ~/.metaflowconfig/)
‚îú‚îÄ‚îÄ requirements.txt        # Depend√™ncias Python para ambiente local (opcional)
‚îú‚îÄ‚îÄ k8s/                    # (Opcional) Manifestos Kubernetes customizados, se houver
‚îÇ   ‚îú‚îÄ‚îÄ secrets/
‚îÇ   ‚îî‚îÄ‚îÄ issuers/
‚îú‚îÄ‚îÄ notebooks/              # (Opcional) Jupyter notebooks para explora√ß√£o e an√°lise
‚îú‚îÄ‚îÄ data/                   # (Opcional) Pequenos datasets de exemplo locais
‚îú‚îÄ‚îÄ tests/                  # (Opcional) Testes unit√°rios ou de integra√ß√£o
‚îú‚îÄ‚îÄ README.md               # Este arquivo
‚îî‚îÄ‚îÄ BACKLOG.md              # Backlog detalhado do projeto
```